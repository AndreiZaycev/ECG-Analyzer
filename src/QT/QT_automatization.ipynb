{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGWclBYKB3qq"
      },
      "outputs": [],
      "source": [
        "!pip install wfdb\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb.processing\n",
        "import pandas as pd\n",
        "!pip install matplotlib==3.1.3\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVVNqbX5CkWm"
      },
      "outputs": [],
      "source": [
        "# Downloading database\n",
        "name_column = 's0010_re'\n",
        "q_onset_column = 1340\n",
        "t_end_column = 1756\n",
        "df = pd.read_excel('/content/qt.xlsx')\n",
        "list_of_ecg = [name_column]\n",
        "previous_patient = 'patient001'\n",
        "for index, name in enumerate(df[name_column]):\n",
        "  if df.patient1[index] == 'patient285':\n",
        "    continue\n",
        "  print(previous_patient)\n",
        "  if not pd.isna(df.patient1[index]):\n",
        "    num = str(df.patient1[index][7:])\n",
        "    if len(num) == 1:\n",
        "      num = f'00{num}'\n",
        "    elif len(num) == 2:\n",
        "      num = f'0{num}'\n",
        "    previous_patient = f'{df.patient1[index][:-int(len(str(df.patient1[index][7:])))]}{num}'\n",
        "  list_of_ecg.append(wfdb.rdrecord(name, sampto=int(df[t_end_column][index]) + 5000, \n",
        "                                     pn_dir = f'ptbdb/{previous_patient}',\n",
        "                                     channels=[0]))\n",
        "list_of_ecg[0] = wfdb.rdrecord(list_of_ecg[0], sampto=int(t_end_column) + 5000, \n",
        "                                     pn_dir = 'ptbdb/patient001',\n",
        "                                     channels=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TaFgJc_gFhWk"
      },
      "outputs": [],
      "source": [
        "# Preparing data\n",
        "list_of_q_onset = df[q_onset_column]\n",
        "q_onset = [int(q_onset_column)]\n",
        "list_of_t_end = df[t_end_column]\n",
        "t_end = [int(t_end_column)]\n",
        "for i in range(len(list_of_q_onset)):\n",
        "  if list_of_q_onset[i] == 0:\n",
        "    continue\n",
        "  else:\n",
        "    q_onset.append(list_of_q_onset[i])\n",
        "    t_end.append(list_of_t_end[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WASEJN9F_w5",
        "outputId": "0d1cc1b7-c422-4188-f5e2-9200e54db4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, iirnotch, lfilter\n",
        "from scipy.signal import butter, sosfilt, sosfilt_zi, sosfiltfilt, lfilter, lfilter_zi, filtfilt, sosfreqz, resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A8B9HNH7H2AQ"
      },
      "outputs": [],
      "source": [
        "# Functions to remove noises\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], analog=False, btype=\"band\", output=\"sos\")\n",
        "    return sos\n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sosfilt(sos,\n",
        "                data)  \n",
        "    return y\n",
        "\n",
        "\n",
        "def butter_bandpass_filter_once(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    zi = sosfilt_zi(sos)\n",
        "    z, _ = sosfilt(sos, data, zi=zi * data[0])\n",
        "    return sos, z, zi\n",
        "\n",
        "\n",
        "def butter_bandpass_filter_again(sos, z, zi):\n",
        "    z2, _ = sosfilt(sos, z, zi=zi * z[0])\n",
        "    return z2\n",
        "\n",
        "\n",
        "def butter_bandpass_forward_backward_filter(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sosfiltfilt(sos,data, axis = 0) \n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ns1VWz6_H5YX"
      },
      "outputs": [],
      "source": [
        "# Removing noises\n",
        "lowcut = 1 \n",
        "highcut = 20\n",
        "copy_ecg = list_of_ecg.copy()\n",
        "for i in range(len(copy_ecg)):\n",
        "  fs = list_of_ecg[i].fs\n",
        "  copy_ecg[i] = butter_bandpass_forward_backward_filter(copy_ecg[i].p_signal, lowcut, highcut, fs, order=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing the ECG graph into two sizes 100 and 600\n",
        "splitted = copy_ecg.copy()\n",
        "q_split = []\n",
        "t_split = []\n",
        "q0 = []\n",
        "t0 = []\n",
        "for i in range(len(splitted)):\n",
        "  min_bpm = 20\n",
        "  max_bpm = 230\n",
        "  search_radius = int(60 * list_of_ecg[i].fs / max_bpm)\n",
        "  qrs_inds = wfdb.processing.qrs.gqrs_detect(sig=splitted[i], fs=list_of_ecg[i].fs)\n",
        "  peaks = wfdb.processing.correct_peaks(splitted[i].flatten(), peak_inds=qrs_inds,\n",
        "                      search_radius=search_radius,\n",
        "                     smooth_window_size = 150, peak_dir='up')\n",
        "  left_slice = 0\n",
        "  right_slice = 0\n",
        "  if len(peaks) == 0 or peaks[0] > t_end[i] + 1000:\n",
        "    continue\n",
        "  p = 0\n",
        "  for indexes in range(len(peaks)):\n",
        "    if peaks[indexes] > q_onset[i] and len(peaks) > 1:\n",
        "        left_slice = peaks[indexes] - 100\n",
        "        right_slice = peaks[indexes] + 600\n",
        "        break\n",
        "  q_split.append(splitted[i][left_slice:peaks[indexes]])\n",
        "  t_split.append(splitted[i][peaks[indexes]:right_slice])\n",
        "  q0.append(q_onset[i] - left_slice)\n",
        "  t0.append(t_end[i] - peaks[indexes])"
      ],
      "metadata": {
        "id": "qz7PMGqfQTrb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing inappropriate ECGs\n",
        "new_t_split = []\n",
        "new_q_split = []\n",
        "new_q = []\n",
        "new_t = []\n",
        "for i in range(len(q_split)):\n",
        "  if t0[i] > len(t_split) or t0[i] < 0 or q0[i] < 0:\n",
        "    continue\n",
        "  new_t_split.append(t_split[i])\n",
        "  new_q_split.append(q_split[i])\n",
        "  new_q.append(q0[i])\n",
        "  new_t.append(t0[i])"
      ],
      "metadata": {
        "id": "cxoUmEgmSJYM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eR-XQBorvo6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5712c335-b3a8-4803-b603-21eba5f8289d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting and MAE for Q onset by XGBoost\n",
        "for i in range(len(new_q_split)):\n",
        "  new_q_split[i] = new_q_split[i].flatten()\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_q_split, new_q, test_size=0.10, random_state=12)\n",
        "from xgboost import XGBRegressor\n",
        "md = XGBRegressor(n_estimators=100, max_depth=3, eta=0.1, subsample=0.8, colsample_bytree=0.9, random_state=1024)\n",
        "md.fit(train_x, train_y)\n",
        "y_pred = md.predict(test_x)\n",
        "mean_absolute_error(y_pred, test_y)"
      ],
      "metadata": {
        "id": "8jRePJpaVyts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d829bc4-4d04-47da-9271-bca7438b41c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:38:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.372880150290096"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting and MAE for T end by XGBoost\n",
        "for i in range(len(new_t_split)):\n",
        "  new_t_split[i] = new_t_split[i].flatten()\n",
        "train_x_t, test_x_t, train_y_t, test_y_t = train_test_split(new_t_split, new_t, test_size=0.10, random_state=12)\n",
        "md1 = XGBRegressor(n_estimators=1000, max_depth=3, eta=0.1, subsample=0.7, colsample_bytree=0.9, random_state=12)\n",
        "md1.fit(train_x_t, train_y_t)\n",
        "y_pred_t = md1.predict(test_x_t)\n",
        "mean_absolute_error(test_y_t, y_pred_t)"
      ],
      "metadata": {
        "id": "DaEh-5ZHyMbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba196146-aba1-4acd-9a5b-1cb7ba048426"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:38:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.72509765625"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "from numpy import absolute\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
        "scores = cross_val_score(md, new_q_split, new_q, scoring='neg_mean_absolute_error', cv=cv)\n",
        "scores1 = cross_val_score(md1, new_t_split, new_t, scoring='neg_mean_absolute_error', cv=cv)"
      ],
      "metadata": {
        "id": "2GGIFDK31fwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric value for Q with cross-validation\n",
        "absolute(scores).mean()"
      ],
      "metadata": {
        "id": "-RDkvQQy3Fzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901999b2-8157-40b0-cb87-50e7ca729e57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.4914148393518785"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric value for Q with cross-validation\n",
        "absolute(scores1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNhp5pSYZln_",
        "outputId": "28ff22b1-bbba-4569-e46d-bdff829942d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.74728504973767"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot some ecgs to see the result of predictions \n",
        "for i in range(20):\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(list(test_x[i]) + list(test_x_t[i]))\n",
        "  ax.axvline(y_pred[i], color='r')\n",
        "  ax.axvline(y_pred_t[i] + 100, color='r')\n",
        "  ax.axvline(test_y_t[i] + 100, color='g')\n",
        "  ax.axvline(test_y[i], color='g')"
      ],
      "metadata": {
        "id": "P6a9-_8yXgA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAE of QT interval \n",
        "interval_length = [0.] * len(y_pred)\n",
        "annotated_interval_length = [0.] * len(y_pred)\n",
        "for i in range(len(interval_length)):\n",
        "  interval_length[i] = y_pred_t[i] - y_pred[i]\n",
        "  annotated_interval_length[i] = test_y_t[i] - test_y[i]\n",
        "mean_absolute_error(interval_length, annotated_interval_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQvT84Y3Zn19",
        "outputId": "11b31b15-7be7-461f-ea4a-db57679eeff2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.83188045726103"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWO-7ZuZDPDK"
      },
      "outputs": [],
      "source": [
        "# Measurements of metrics for different models for Q onset\n",
        "model = Ridge(100, random_state=42)\n",
        "model1 = Lasso(1, random_state=42)\n",
        "model2 = GradientBoostingRegressor(max_depth=5, criterion=\"absolute_error\", random_state=42)\n",
        "model3 = GradientBoostingRegressor(max_depth=4, criterion=\"absolute_error\", random_state=42)\n",
        "model4 = GradientBoostingRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model5 = GradientBoostingRegressor(max_depth=2, criterion=\"absolute_error\", random_state=42)\n",
        "model6 = RandomForestRegressor(max_depth=5, criterion=\"absolute_error\", random_state=42)\n",
        "model7 = RandomForestRegressor(max_depth=4, criterion=\"absolute_error\", random_state=42)\n",
        "model8 = RandomForestRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model9 = RandomForestRegressor(max_depth=2, criterion=\"absolute_error\", random_state=42)\n",
        "Mmodel2 = GradientBoostingRegressor(max_depth=5,  random_state=42)\n",
        "Mmodel3 = GradientBoostingRegressor(max_depth=4,  random_state=42)\n",
        "Mmodel4 = GradientBoostingRegressor(max_depth=3,  random_state=42)\n",
        "Mmodel5 = GradientBoostingRegressor(max_depth=2,  random_state=42)\n",
        "Mmodel6 = RandomForestRegressor(max_depth=5,  random_state=42)\n",
        "Mmodel7 = RandomForestRegressor(max_depth=4,  random_state=42)\n",
        "Mmodel8 = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "Mmodel9 = RandomForestRegressor(max_depth=2, random_state=42)\n",
        "lst_of_models = [model, model1, model2, model3, model4, model5, model6, model7, model8, model9,\n",
        "                Mmodel2, Mmodel3, Mmodel4, Mmodel5, Mmodel6, Mmodel7, Mmodel8, Mmodel9]\n",
        "lst_of_deviation = [0.] * 18\n",
        "for x, i in enumerate(lst_of_models):\n",
        "  i.fit(train_x, train_y)\n",
        "  pr = i.predict(test_x)\n",
        "  lst_of_deviation[x] = mean_absolute_error(test_y, pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb8z4ZktL7vx"
      },
      "outputs": [],
      "source": [
        "lst_of_titles = [ \n",
        "                 \"Ridge(100)\",\n",
        "                 \"Lasso(1)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=5, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=4, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=3, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=2, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=5, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=4, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=3, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=2, absolute error)\"\n",
        "                 \"GradientBoostingRegressor(max_depth=5)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=4)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=3)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=2)\",\n",
        "                 \"RandomForestRegressor(max_depth=5)\",\n",
        "                 \"RandomForestRegressor(max_depth=4)\",\n",
        "                 \"RandomForestRegressor(max_depth=3)\",\n",
        "                 \"RandomForestRegressor(max_depth=2)\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHJ7gFj5NDrg"
      },
      "outputs": [],
      "source": [
        "for i in range(len(lst_of_titles)):\n",
        "  print(f\"{lst_of_titles[i]} MAE: {lst_of_deviation[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnEmFIM4ROKU"
      },
      "outputs": [],
      "source": [
        "# Measurements of metrics for different models for T onset\n",
        "lst_of_deviation = [0.] * 18\n",
        "for x, i in enumerate(lst_of_models):\n",
        "  i.fit(train_x_t, train_y_t)\n",
        "  pr = i.predict(test_x_t)\n",
        "  lst_of_deviation[x] = mean_absolute_error(test_y_t, pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nWUWPMFSTZA"
      },
      "outputs": [],
      "source": [
        "for i in range(len(lst_of_titles)):\n",
        "  print(f\"{lst_of_titles[i]} MAE: {lst_of_deviation[i]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "QT automatization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}