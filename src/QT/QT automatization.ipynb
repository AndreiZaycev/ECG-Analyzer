{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGWclBYKB3qq"
      },
      "source": [
        "!pip install wfdb\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb.processing\n",
        "import pandas as pd\n",
        "!pip install matplotlib==3.1.3\n",
        "import numpy as np \n",
        "\n",
        "\n",
        "name_column = 's0010_re'\n",
        "q_onset_column = 1340\n",
        "t_end_column = 1756\n",
        "df = pd.read_excel('/content/qt.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVVNqbX5CkWm"
      },
      "source": [
        "list_of_ecg = [name_column]\n",
        "previous_patient = 'patient001'\n",
        "for index, name in enumerate(df[name_column]):\n",
        "  if df.patient1[index] == 'patient285':\n",
        "    continue\n",
        "  print(previous_patient)\n",
        "  if not pd.isna(df.patient1[index]):\n",
        "    num = str(df.patient1[index][7:])\n",
        "    if len(num) == 1:\n",
        "      num = f'00{num}'\n",
        "    elif len(num) == 2:\n",
        "      num = f'0{num}'\n",
        "    previous_patient = f'{df.patient1[index][:-int(len(str(df.patient1[index][7:])))]}{num}'\n",
        "  list_of_ecg.append(wfdb.rdrecord(name, sampto=int(df[t_end_column][index]) + 5000, \n",
        "                                     pn_dir = f'ptbdb/{previous_patient}',\n",
        "                                     channels=[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMvPNwyWFgtE"
      },
      "source": [
        "list_of_ecg[0] = wfdb.rdrecord(list_of_ecg[0], sampto=int(t_end_column) + 5000, \n",
        "                                     pn_dir = 'ptbdb/patient001',\n",
        "                                     channels=[0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFgJc_gFhWk"
      },
      "source": [
        "list_of_q_onset = df[q_onset_column]\n",
        "q_onset = [int(q_onset_column)]\n",
        "list_of_t_end = df[t_end_column]\n",
        "t_end = [int(t_end_column)]\n",
        "for i in range(len(list_of_q_onset)):\n",
        "  if list_of_q_onset[i] == 0:\n",
        "    continue\n",
        "  else:\n",
        "    q_onset.append(list_of_q_onset[i])\n",
        "    t_end.append(list_of_t_end[i])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WASEJN9F_w5"
      },
      "source": [
        "!pip install scipy\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, iirnotch, lfilter\n",
        "from scipy.signal import butter, sosfilt, sosfilt_zi, sosfiltfilt, lfilter, lfilter_zi, filtfilt, sosfreqz, resample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8B9HNH7H2AQ"
      },
      "source": [
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], analog=False, btype=\"band\", output=\"sos\")\n",
        "    return sos\n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sosfilt(sos,\n",
        "                data)  \n",
        "    return y\n",
        "\n",
        "\n",
        "def butter_bandpass_filter_once(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    zi = sosfilt_zi(sos)\n",
        "    z, _ = sosfilt(sos, data, zi=zi * data[0])\n",
        "    return sos, z, zi\n",
        "\n",
        "\n",
        "def butter_bandpass_filter_again(sos, z, zi):\n",
        "    z2, _ = sosfilt(sos, z, zi=zi * z[0])\n",
        "    return z2\n",
        "\n",
        "\n",
        "def butter_bandpass_forward_backward_filter(data, lowcut, highcut, fs, order=5):\n",
        "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sosfiltfilt(sos,data, axis = 0) \n",
        "    return y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns1VWz6_H5YX"
      },
      "source": [
        "lowcut = 1 \n",
        "highcut = 20\n",
        "copy_ecg = list_of_ecg.copy()\n",
        "for i in range(len(copy_ecg)):\n",
        "  fs = list_of_ecg[i].fs\n",
        "  copy_ecg[i] = butter_bandpass_forward_backward_filter(copy_ecg[i].p_signal, lowcut, highcut, fs, order=4)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edB2Z1NeQqin"
      },
      "source": [
        "k = 23\n",
        "min_bpm = 20\n",
        "max_bpm = 230\n",
        "search_radius = int(60 * list_of_ecg[k].fs / max_bpm)\n",
        "qrs_inds = wfdb.processing.qrs.gqrs_detect(sig=copy_ecg[k], fs=list_of_ecg[k].fs)\n",
        "peaks = wfdb.processing.correct_peaks(copy_ecg[k].flatten(), peak_inds=qrs_inds,\n",
        "                    search_radius=search_radius,\n",
        "                    smooth_window_size = 150, peak_dir='up')\n",
        "left_slice = 0\n",
        "right_slice = 0\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(copy_ecg[k])\n",
        "for j in peaks:\n",
        "  ax.axvline(x=j, color='g')\n",
        "for indexes in range(len(peaks)):\n",
        "  if peaks[indexes] > q_onset[k]:\n",
        "    if indexes == 0:\n",
        "      left_slice = 0\n",
        "    else:\n",
        "      left_slice = peaks[indexes - 1]\n",
        "    right_slice = peaks[indexes + 1]\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_gbrXwaJDgY"
      },
      "source": [
        "sliced_ecg = copy_ecg.copy()\n",
        "ecg_peak = []\n",
        "ecg = []\n",
        "q = []\n",
        "t = []\n",
        "for i in range(len(sliced_ecg)):\n",
        "  min_bpm = 20\n",
        "  max_bpm = 230\n",
        "  search_radius = int(60 * list_of_ecg[i].fs / max_bpm)\n",
        "  qrs_inds = wfdb.processing.qrs.gqrs_detect(sig=sliced_ecg[i], fs=list_of_ecg[i].fs)\n",
        "  peaks = wfdb.processing.correct_peaks(sliced_ecg[i].flatten(), peak_inds=qrs_inds,\n",
        "                      search_radius=search_radius,\n",
        "                     smooth_window_size = 150, peak_dir='up')\n",
        "  left_slice = 0\n",
        "  right_slice = 0\n",
        "  if len(peaks) == 0 or peaks[0] > t_end[i] + 1000:\n",
        "    continue\n",
        "  p = 0\n",
        "  for indexes in range(len(peaks)):\n",
        "    if peaks[indexes] > q_onset[i] and len(peaks) > 1:\n",
        "      if indexes == 0:\n",
        "        left_slice = 0\n",
        "      else:\n",
        "        left_slice = peaks[indexes - 1]\n",
        "      right_slice = peaks[indexes + 1]\n",
        "      p = indexes\n",
        "      break\n",
        "  ecg.append(sliced_ecg[i][left_slice:right_slice])\n",
        "  ecg_peak.append(p)\n",
        "  q.append(q_onset[i] - left_slice)\n",
        "  t.append(t_end[i] - left_slice)\n",
        "fig, ax = plt.subplots()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THQF94SNon0N"
      },
      "source": [
        "final_ecg = []\n",
        "final_q = []\n",
        "peak = []\n",
        "final_t = []\n",
        "for i,x in enumerate(ecg):\n",
        "  if len(x) > 800:\n",
        "    final_ecg.append(x)\n",
        "    final_q.append(q[i])\n",
        "    peak.append(ecg_peak[i])\n",
        "    final_t.append(t[i])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sx95y5BJ5zB"
      },
      "source": [
        "min_ecg_length = 800\n",
        "lst_of_ecg = []\n",
        "q = []\n",
        "t = [] \n",
        "p = []\n",
        "for i in range(len(final_ecg)):\n",
        "  ecg = final_ecg[i]\n",
        "  distance = len(ecg) - min_ecg_length\n",
        "  if distance % 3 == 0:\n",
        "    left = (distance // 3) * 2 \n",
        "    right = len(ecg) - (distance // 3)\n",
        "  elif distance % 3 == 1:\n",
        "    left = (distance // 3) * 2\n",
        "    right = len(ecg) - (distance // 3) - 1\n",
        "  else:\n",
        "    left = (distance // 3) * 2\n",
        "    right = len(ecg) - (distance // 3) - 2\n",
        "  if left > peak[i] and peak[i] > 0:\n",
        "    if left < 50:\n",
        "      right -= left\n",
        "      left = 0 \n",
        "    else:\n",
        "      left -= 50\n",
        "      right -= 50\n",
        "  if (final_q[i] - left < 0):\n",
        "    continue\n",
        "  lst_of_ecg.append(ecg[left:right])\n",
        "  q.append(final_q[i] - left)\n",
        "  t.append(final_t[i] - left)\n",
        "  p.append(peak[i] - left)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR-XQBorvo6B"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BJHHmV-weAj"
      },
      "source": [
        "for i in range(len(lst_of_ecg)):\n",
        "  lst_of_ecg[i] = lst_of_ecg[i].flatten()\n",
        "train_x, test_x, train_y, test_y = train_test_split(lst_of_ecg, q, test_size=0.05, random_state=42)\n",
        "model = GradientBoostingRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model.fit(train_x, train_y)\n",
        "y_pred = model.predict(test_x)\n",
        "mean_absolute_error(test_y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_t, test_x_t, train_y_t, test_y_t = train_test_split(lst_of_ecg, t, test_size=0.05, random_state=42)\n",
        "model_t = GradientBoostingRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model_t.fit(train_x_t, train_y_t)\n",
        "y_pred_t = model_t.predict(test_x_t)\n",
        "mean_absolute_error(test_y_t, y_pred_t)"
      ],
      "metadata": {
        "id": "yeoDmLBAe-07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measurements of metrics for different models for Q onset\n",
        "model = Ridge(100, random_state=42)\n",
        "model1 = Lasso(1, random_state=42)\n",
        "model2 = GradientBoostingRegressor(max_depth=5, criterion=\"absolute_error\", random_state=42)\n",
        "model3 = GradientBoostingRegressor(max_depth=4, criterion=\"absolute_error\", random_state=42)\n",
        "model4 = GradientBoostingRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model5 = GradientBoostingRegressor(max_depth=2, criterion=\"absolute_error\", random_state=42)\n",
        "model6 = RandomForestRegressor(max_depth=5, criterion=\"absolute_error\", random_state=42)\n",
        "model7 = RandomForestRegressor(max_depth=4, criterion=\"absolute_error\", random_state=42)\n",
        "model8 = RandomForestRegressor(max_depth=3, criterion=\"absolute_error\", random_state=42)\n",
        "model9 = RandomForestRegressor(max_depth=2, criterion=\"absolute_error\", random_state=42)\n",
        "Mmodel2 = GradientBoostingRegressor(max_depth=5,  random_state=42)\n",
        "Mmodel3 = GradientBoostingRegressor(max_depth=4,  random_state=42)\n",
        "Mmodel4 = GradientBoostingRegressor(max_depth=3,  random_state=42)\n",
        "Mmodel5 = GradientBoostingRegressor(max_depth=2,  random_state=42)\n",
        "Mmodel6 = RandomForestRegressor(max_depth=5,  random_state=42)\n",
        "Mmodel7 = RandomForestRegressor(max_depth=4,  random_state=42)\n",
        "Mmodel8 = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "Mmodel9 = RandomForestRegressor(max_depth=2, random_state=42)\n",
        "lst_of_models = [model, model1, model2, model3, model4, model5, model6, model7, model8, model9,\n",
        "                Mmodel2, Mmodel3, Mmodel4, Mmodel5, Mmodel6, Mmodel7, Mmodel8, Mmodel9]\n",
        "lst_of_deviation = [0.] * 18\n",
        "for x, i in enumerate(lst_of_models):\n",
        "  i.fit(train_x, train_y)\n",
        "  pr = i.predict(test_x)\n",
        "  lst_of_deviation[x] = mean_absolute_error(test_y, pr)"
      ],
      "metadata": {
        "id": "TWO-7ZuZDPDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_of_titles = [ \n",
        "                 \"Ridge(100)\",\n",
        "                 \"Lasso(1)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=5, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=4, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=3, absolute error)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=2, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=5, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=4, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=3, absolute error)\",\n",
        "                 \"RandomForestRegressor(max_depth=2, absolute error)\"\n",
        "                 \"GradientBoostingRegressor(max_depth=5)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=4)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=3)\",\n",
        "                 \"GradientBoostingRegressor(max_depth=2)\",\n",
        "                 \"RandomForestRegressor(max_depth=5)\",\n",
        "                 \"RandomForestRegressor(max_depth=4)\",\n",
        "                 \"RandomForestRegressor(max_depth=3)\",\n",
        "                 \"RandomForestRegressor(max_depth=2)\"\n",
        "]"
      ],
      "metadata": {
        "id": "Wb8z4ZktL7vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(lst_of_titles)):\n",
        "  print(f\"{lst_of_titles[i]} MAE: {lst_of_deviation[i]}\")"
      ],
      "metadata": {
        "id": "dHJ7gFj5NDrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interval_length = [0.] * len(y_pred)\n",
        "annotated_interval_length = [0.] * len(y_pred)\n",
        "for i in range(len(interval_length)):\n",
        "  interval_length[i] = y_pred_t[i] - y_pred[i]\n",
        "  annotated_interval_length[i] = test_y_t[i] - test_y[i]\n",
        "mean_absolute_error(interval_length, annotated_interval_length)"
      ],
      "metadata": {
        "id": "jym7ypjzWp5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BG20zuercVy"
      },
      "source": [
        "# Check deviation of test dataset\n",
        "import statistics\n",
        "import math \n",
        "dev = statistics.pvariance(test_y_t)\n",
        "dev = math.sqrt(dev)\n",
        "dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = statistics.pvariance(test_y)\n",
        "dev = math.sqrt(dev)\n",
        "dev"
      ],
      "metadata": {
        "id": "qLnnmPFu1Lrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measurements of metrics for different models for T onset\n",
        "lst_of_deviation = [0.] * 18\n",
        "for x, i in enumerate(lst_of_models):\n",
        "  i.fit(train_x_t, train_y_t)\n",
        "  pr = i.predict(test_x_t)\n",
        "  lst_of_deviation[x] = mean_absolute_error(test_y_t, pr)"
      ],
      "metadata": {
        "id": "XnEmFIM4ROKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(lst_of_titles)):\n",
        "  print(f\"{lst_of_titles[i]} MAE: {lst_of_deviation[i]}\")"
      ],
      "metadata": {
        "id": "8nWUWPMFSTZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}